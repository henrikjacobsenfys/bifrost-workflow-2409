{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b699a49c-625d-4d04-8d2b-73acd751b7d3",
   "metadata": {},
   "source": [
    "In this notebook, we will analyse the simulated data using EasyScience. As EasyScience is still under development, there are some quirks. The only notable one here is that we need to install a particular branch of it, which can be done using the following command:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/EasyScience/EasyScience.git@numpy2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import plopp as pp\n",
    "import scippneutron as scn\n",
    "import scippnexus as snx\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from easyscience.Objects.new_variable import Parameter\n",
    "from easyscience.Objects.ObjectClasses import BaseObj\n",
    "from easyscience.fitting import Fitter\n",
    "import matplotlib.pyplot as plt\n",
    "from ess.spectroscopy.indirect import bifrost\n",
    "from bifrost2409.config import POOCH_DATA_DIR, INTERIM_DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92e0648-5728-4c28-8924-7bd8563cfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"20240914/BIFROST_20240914T053723.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a2687",
   "metadata": {},
   "source": [
    "We will load the data just like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b0f0d7-fca1-4280-b6ac-e9a96d8171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['energy_momentum_events']\n",
    "target_files = {target: INTERIM_DATA_DIR / f'{Path(datafile).stem}_{target}.h5' for target in targets}\n",
    "if all(file.exists() for file in target_files.values()):\n",
    "    from scipp.io import load_hdf5\n",
    "    objects = {target: load_hdf5(file) for target, file in target_files.items()}\n",
    "else:\n",
    "    data = bifrost(POOCH_DATA_DIR / datafile, is_simulated=True)\n",
    "    objects = {target: data[target] for target in targets}\n",
    "    for target in targets:\n",
    "        objects[target].save_hdf5(target_files[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1d7921-1934-4088-9057-1fbf8827cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_momentum_events = objects['energy_momentum_events']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5d46c",
   "metadata": {},
   "source": [
    "Let us have a look at the data again, before we decide how to analyse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175247e5-2c8c-4d68-ba81-21c9b7f1feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_E_plane(events, q_x_range, q_bins, e_bins):\n",
    "    # Creates a histogram of intensity as function of energy transfer and Q_x\n",
    "    # events: scipp dataset with the events to be binned\n",
    "    # q_x_range: scipp variable with the range of Q_x values to bin in\n",
    "    # q_bins: The number of bins in q\n",
    "    # e_bins: The number of bins in energy transfer\n",
    "    \n",
    "    a = events.bin(table_momentum_x=q_x_range)\n",
    "    # Remove coordinates and event coordinates that we're not using:\n",
    "    for coord in ('a3', 'a4', 'detector_number', 'final_energy'):\n",
    "        del a.coords[coord]\n",
    "    for coord in ('event_time_offset', 'event_time_zero', 'frame_time', 'incident_energy', 'lab_momentum_x', 'lab_momentum_z'):\n",
    "        del a.bins.coords[coord]\n",
    "    # drop the non-energy_transfer dimensions before binning in Q\n",
    "    for dim in ('setting', 'event_id'):\n",
    "        a = a.bins.concat(dim)\n",
    "    return a.bin(energy_transfer=e_bins, table_momentum_z=q_bins).hist()['table_momentum_x', 0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfb09f3-6ab1-43d8-a1f0-70fe8501a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "astar = 2 * np.pi / 6.56162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_events=hist_E_plane(energy_momentum_events, sc.array(values=[2 * astar - 0.2,  2 * astar + 0.2], dims=['table_momentum_x'], unit='1/angstrom'), 200, 50)\n",
    "my_events.plot(norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791205b6",
   "metadata": {},
   "source": [
    "We want to fit this data by taking 1-dimensional \"cuts\" at various constant values of Q, and determine the position of the peak from the phonon. We will fit these peak positions to a Gaussian.\n",
    "Taking cuts of the full data set is inefficient, so we first prepare the data by removing the coordinates that we don't need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a3b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_cut(events):\n",
    "    # Prepare the data for a cut in Q, by removing the coordinates that we're not using\n",
    "    q_x_range=sc.array(values=[2 * astar - 0.2,  2 * astar + 0.2], dims=['table_momentum_x'], unit='1/angstrom')\n",
    "    q_z_range=sc.array(values=[-2 * astar,  2 * astar], dims=['table_momentum_z'], unit='1/angstrom')\n",
    "    a = events.bin(table_momentum_x=q_x_range,table_momentum_z=q_z_range)\n",
    "    # Remove coordinates and event coordinates that we're not using:\n",
    "    for coord in ('a3', 'a4', 'detector_number', 'final_energy'):\n",
    "        del a.coords[coord]\n",
    "    for coord in ('event_time_offset', 'event_time_zero', 'frame_time', 'incident_energy', 'lab_momentum_x', 'lab_momentum_z'):\n",
    "        del a.bins.coords[coord]\n",
    "    # drop the non-energy_transfer dimensions before binning in Q\n",
    "    for dim in ('setting', 'event_id'):\n",
    "        a = a.bins.concat(dim)    \n",
    "    return a\n",
    "    \n",
    "prepared_data=prepare_data_for_cut(energy_momentum_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a62f9",
   "metadata": {},
   "source": [
    "We now define a function to make cuts at constant Q. Many of the bins have zero count, and in these cases, the variance is also zero. A normal chi square fit cannot handle this, so we artifically add 1 to the variance. It is also possible to fit the data using the Poisson likelihood instead, but we save that for another day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_Q_cut(events, q_z_value,q_z_width,E_bins,E_min,E_max):\n",
    "    # Creates a histogram of intensity as function of energy transfer for a given Q_z value\n",
    "    # events: scipp dataset with the events to be binned\n",
    "    # q_z_value: The Q_z value to cut at\n",
    "    # q_z_width: The width of the cut\n",
    "    # E_bins: The number of bins in energy transfer\n",
    "    # E_min: The minimum energy transfer as a scipp variable\n",
    "    # E_max: The maximum energy transfer as a scipp variable\n",
    "    q_z_range=sc.array(values=[q_z_value.value - q_z_width.value/2, q_z_value.value + q_z_width.value/2], dims=['table_momentum_z'],unit='1/angstrom')\n",
    "    a = events.bin(table_momentum_z=q_z_range)\n",
    "    a=a.bin(energy_transfer=E_bins).hist()\n",
    "\n",
    "    a = a.assign_coords(energy_transfer=sc.midpoints(a.coords['energy_transfer']))\n",
    "    a=a['table_momentum_x', 0]['table_momentum_z', 0]    \n",
    "    a.variances = a.values+1.0\n",
    "\n",
    "    a=a['energy_transfer',E_min:E_max]\n",
    "\n",
    "    return a\n",
    "\n",
    "#Test the function. Notice how we define units using scipp.\n",
    "Q_cut_center = 1.0 * sc.Unit('1/angstrom')\n",
    "Q_cut_width = 0.1 * sc.Unit('1/angstrom')\n",
    "E_bins = 201\n",
    "E_min = -0.1 * sc.Unit('meV')\n",
    "E_max = 2 * sc.Unit('meV')\n",
    "mycut=const_Q_cut(prepared_data,Q_cut_center,Q_cut_width,E_bins,E_min,E_max)\n",
    "mycut.plot(norm='log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdff36",
   "metadata": {},
   "source": [
    "Let us assume that the data can be fitted with a Gaussian plus a background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a876c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate the Gaussian + background model for fitting. \n",
    "# When using EasyScience, you don't give the input parameters to the function.\n",
    "def gaussian_model(E: np.ndarray) -> np.ndarray:\n",
    "    y= A.value * np.exp(-((E - E0.value) ** 2) / (2 * sigma.value ** 2)) + B.value\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let us first do a single cut and fit to see how the fitting works\n",
    "# Create a cut\n",
    "Q_cut_center = 1.0* sc.Unit('1/angstrom') \n",
    "Q_cut_width = 0.1* sc.Unit('1/angstrom')\n",
    "E_bins=201\n",
    "E_min=1.1*sc.Unit('meV')\n",
    "E_max=2*sc.Unit('meV')\n",
    "\n",
    "this_data=const_Q_cut(prepared_data,Q_cut_center,Q_cut_width,201,E_min,E_max)\n",
    "\n",
    "# For EasyScience we extract the raw values and errors\n",
    "E_values=this_data.coords['energy_transfer'].values\n",
    "intensity_cut=this_data.values\n",
    "intensity_error_cut=np.sqrt(this_data.variances)\n",
    "\n",
    "# Define the Gaussian parameters to fit (A = amplitude, E0 = center, sigma = width, B = background)\n",
    "# We give sensible start values for all parameters\n",
    "A =     Parameter(name='A',     value=np.max(intensity_cut),              fixed=False,min=0)\n",
    "E0 =    Parameter(name='E0',    value=E_values[np.argmax(intensity_cut)], fixed=False)\n",
    "sigma = Parameter(name='sigma', value=0.05,                               fixed=False,min=0)\n",
    "B =     Parameter(name='B',     value=np.min(intensity_cut),              fixed=False)\n",
    "\n",
    "# Create an EasyScience Base Object, containing the Gaussian function and its parameters. \n",
    "gaussian = BaseObj(name='gaussian', A=A, E0=E0, sigma=sigma, B=B)\n",
    "\n",
    "# Create the Fitter object\n",
    "fitter = Fitter(gaussian, gaussian_model)\n",
    "\n",
    "# Fit the data for this cut. Here, weights are the inverse of the errors in order to emphasize the peak more than the background\n",
    "res = fitter.fit(x=E_values, y=intensity_cut,weights=1/intensity_error_cut)\n",
    "\n",
    "# Show the fit results\n",
    "print(f\"Q_cut_center: {round(Q_cut_center.value, 2)}, {A}, {E0}, {sigma}, {B}\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.errorbar(E_values, intensity_cut, intensity_error_cut, label='Data',marker='o',markerfacecolor='w',linestyle='None')\n",
    "E_values_fit = np.linspace(E_values[0], E_values[-1], 1000)\n",
    "plt.plot(E_values_fit, gaussian_model(E_values_fit), label='Fit')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We are now ready to loop over all Q cuts and fit the data for each cut\n",
    "# Define the number of cuts and the Q range for the cuts\n",
    "number_of_cuts=15\n",
    "Q_z_start=0.1* sc.Unit('1/angstrom')\n",
    "Q_z_end=1.6* sc.Unit('1/angstrom')\n",
    "\n",
    "Q_cut_centers=sc.linspace('table_momentum_z', Q_z_start, Q_z_end, num=number_of_cuts) # Centers of the Q cuts\n",
    "\n",
    "Q_cut_width = (Q_z_end-Q_z_start)/number_of_cuts  # Width of Q cuts\n",
    "\n",
    "# Define the number of bins and the minimum energy transfer for the fits. To keep things simple, we want to avoid the elastic line\n",
    "E_min=0.1*sc.Unit('meV')\n",
    "E_max=2*sc.Unit('meV')\n",
    "\n",
    "# Store the fit results for each Q cut\n",
    "fit_results = [] \n",
    "\n",
    "\n",
    "# Loop over each Q cut\n",
    "for Q_cut_center in Q_cut_centers:\n",
    "    this_data=const_Q_cut(prepared_data,Q_cut_center,Q_cut_width,E_bins,E_min,E_max)\n",
    "    E_values=this_data.coords['energy_transfer'].values\n",
    "    intensity_cut=this_data.values\n",
    "    intensity_error_cut=np.sqrt(this_data.variances)\n",
    "   \n",
    "\n",
    "    # Define the Gaussian parameters to fit (A = amplitude, E0 = center, sigma = width, B = background)\n",
    "    A =     Parameter(name='A',     value=np.max(intensity_cut),              fixed=False,min=0)\n",
    "    E0 =    Parameter(name='E0',    value=E_values[np.argmax(intensity_cut)], fixed=False)\n",
    "    sigma = Parameter(name='sigma', value=0.05,                               fixed=False,min=0)\n",
    "    B =     Parameter(name='B',     value=np.min(intensity_cut),              fixed=False)\n",
    "    \n",
    "    # Create the base object for the Gaussian\n",
    "    gaussian = BaseObj(name='gaussian', A=A, E0=E0, sigma=sigma, B=B)\n",
    "    # simple_gaussian = BaseObj(name='simple_gaussian', A=A)\n",
    "    \n",
    "    # Create the Fitter object\n",
    "    fitter = Fitter(gaussian, gaussian_model)\n",
    "    # fitter = Fitter(simple_gaussian, gaussian_model)\n",
    "    \n",
    "    # Fit the data for this cut\n",
    "    res = fitter.fit(x=E_values, y=intensity_cut,weights=1/intensity_error_cut)\n",
    "    \n",
    "    # Save the fit parameters for this cut\n",
    "    fit_results.append({\n",
    "        'Q_cut_center': Q_cut_center,\n",
    "        'A': A,\n",
    "        'E0': E0,\n",
    "        'sigma': sigma,\n",
    "        'B': B,\n",
    "        'intensity_cut': intensity_cut,\n",
    "        'intensity_error_cut': intensity_error_cut,\n",
    "        'E_values': E_values\n",
    "    })\n",
    "\n",
    "# Show the fit results\n",
    "for result in fit_results:\n",
    "    print(f\"Q: {round(result['Q_cut_center'].value, 2)}, {result['A']}, {result['E0']}, {result['sigma']}, {result['B']}\")\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i, result in enumerate(fit_results):\n",
    "# for i in range(1):\n",
    "\n",
    "    Q_cut_center = result['Q_cut_center']\n",
    "    A = result['A']\n",
    "    E0 = result['E0']\n",
    "    sigma = result['sigma']\n",
    "    B = result['B']\n",
    "    intensity_cut = result['intensity_cut']\n",
    "    intensity_error_cut = result['intensity_error_cut']\n",
    "    E_values = result['E_values']\n",
    "    \n",
    "    plt.subplot(int(np.ceil(number_of_cuts/3)), 3, i + 1)\n",
    "    plt.errorbar(E_values, intensity_cut, intensity_error_cut, label='Data')\n",
    "    plt.plot(E_values, gaussian_model(E_values), label='Fit')\n",
    "    plt.title(f'Q = {Q_cut_center.value:.2f}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a681c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the fitted parameters for each Q cut\n",
    "Q_values =  np.array([result['Q_cut_center'].value for result in fit_results])  \n",
    "E0_values = np.array([result['E0'].value for result in fit_results]) \n",
    "E0_errors = np.array([result['E0'].error for result in fit_results]) \n",
    "A_values = np.array([result['A'].value for result in fit_results]) \n",
    "A_errors = np.array([result['A'].error for result in fit_results]) \n",
    "\n",
    "# Define the parameter to fit \n",
    "K = Parameter(name='K', value=1.0, fixed=False,min=0)  \n",
    "\n",
    "# Define dispersion\n",
    "def dispersion_model(h: np.ndarray) -> np.ndarray:\n",
    "    astar = 2 * np.pi / 6.56162\n",
    "    return K.value*np.abs(np.sin(np.pi*h/2/astar))\n",
    "\n",
    "# Create a BaseObj and fit the data\n",
    "phonon_dispersion = BaseObj(name='phonon_dispersion', K=K)\n",
    "fitter = Fitter(phonon_dispersion, dispersion_model)\n",
    "res = fitter.fit(x=Q_values, y=E0_values, weights=1/E0_errors)\n",
    "\n",
    "# Extract the fitted parameters\n",
    "fitted_K = K\n",
    "\n",
    "# Print the fitted parameters\n",
    "print(f\"Fitted K: {fitted_K}\")\n",
    "\n",
    "# Optional: Plot the fit against the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate model values using the fitted parameters\n",
    "h_fit = np.linspace(min(Q_values), max(Q_values), 100)\n",
    "E_fit = dispersion_model(h_fit)\n",
    "\n",
    "# Plot the data and the fitted model\n",
    "plt.errorbar(Q_values/astar, E0_values, yerr=E0_errors, fmt='o', label='Data')\n",
    "plt.plot(h_fit/astar, E_fit, label='Fitted Dispersion', color='red')\n",
    "plt.xlabel('Q_z (R.L.U.)')\n",
    "plt.ylabel('E (meV)')\n",
    "plt.title('Fitted phonon dispersion')\n",
    "plt.legend()\n",
    "plt.ylim(0,1.6)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
